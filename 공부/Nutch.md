# ğŸ¸ Apache Nutch ì„¤ì¹˜ ë° ì‚¬ìš©ë²•

## ğŸª ê°œë°œ í™˜ê²½
- Ubuntu 20.04 LTS
- Nutch 1.18  
[ë‹¤ìš´ë§í¬](https://nutch.apache.org/download/)

### 0. JAVA HOME ì„¤ì •
```bash
export JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"
```
### 1. ë‹¤ìš´ë°›ê¸°
```bash
wget https://dlcdn.apache.org/nutch/1.18/apache-nutch-1.18-bin.tar.gz
```
  
### 2. ì••ì¶• í’€ê¸°
```bash
tar -zxvf apache-nutch-1.18-bin.tar.gz
```
  
### 3. data í´ë”, seed í´ë”, íŒŒì¼ ë§Œë“¤ê¸°
```bash
mkdir data
cd data
mkdir seed
vi seed.txt
```

### 4. URL ì„¤ì •
```
vi seed.txt

# URL ì…ë ¥
https://nutch.apache.org/index.html
```

### 5. í¬ë¡¤ë§ í•˜ê¸° ìœ„í•œ ìµœì†Œ ì„¤ì •
```bash
cd conf
vi nutch-site.xml

# Property ì¶”ê°€
<property>
	  <name>http.agent.name</name>
	  <value>test-crawler</value>
	  <description>HTTP 'User-Agent' request header. MUST NOT be empty - 
	  please set this to a single word uniquely related to your organization.

	  NOTE: You should also check other related properties:

	    http.robots.agents
	    http.agent.description
	    http.agent.url
	    http.agent.email
	    http.agent.version

	  and set their values appropriately.

	  </description>
</property>

# í•„í„° ì„¤ì •ì€ vi conf ì—ì„œ urlfilterë“¤ì„ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤.
```

### 6. í¬ë¡¤ë§ ëª…ë ¹ì–´ í™•ì¸ ë° í¬ë¡¤ë§ ì‹¤í–‰
```bash
# nutch ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ë¨¼ì € ì´ë™
bin/crawl

bin/crawl -s {seed_dir} {crawl_dir} {num_rounds}
# bin/crawl -s data/seed data/crawl 3

# bin/crawl -s data/seed --size-fetchlist 500 data/crawl 1
```

### 7. ë°ì´í„° ë³€í™˜
ê¸°ì¡´ì˜ ë°ì´í„°ëŠ” ì•Œì•„ë³´ê¸°ê°€ ì–´ë µë‹¤ ì´ë¥¼ ë³´ê¸° í¸í•˜ê²Œ ë³€ê²½
```bash
# ëª…ë ¹ì–´ í™•ì¸ -> bin/nutch
bin/nutch dump -outputDir {ì¶œë ¥ í´ë”} -segment {segment í´ë”}
# bin/nutch dump -outputDir data/output -segment data/crawl/segments/
```